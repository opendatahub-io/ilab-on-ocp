# PIPELINE DEFINITION
# Name: instructlab
# Description: InstructLab pipeline
# Inputs:
#    final_eval_batch_size: str [Default: 'auto']
#    final_eval_few_shots: int [Default: 5.0]
#    final_eval_max_workers: str [Default: 'auto']
#    final_eval_merge_system_user_message: bool [Default: False]
#    k8s_storage_class_name: str [Default: 'standard']
#    mt_bench_max_workers: str [Default: 'auto']
#    mt_bench_merge_system_user_message: bool [Default: False]
#    sdg_base_model: str [Default: 's3://<BUCKET>/<PATH_TO_MODEL>']
#    sdg_max_batch_len: int [Default: 5000.0]
#    sdg_pipeline: str [Default: '/usr/share/instructlab/sdg/pipelines/agentic']
#    sdg_pregenerated_tarball: str
#    sdg_repo_branch: str
#    sdg_repo_pr: int
#    sdg_repo_url: str [Default: 'https://github.com/instructlab/taxonomy.git']
#    sdg_sample_size: float [Default: 1.0]
#    sdg_scale_factor: int [Default: 30.0]
#    train_effective_batch_size_phase_1: int [Default: 128.0]
#    train_effective_batch_size_phase_2: int [Default: 3840.0]
#    train_learning_rate_phase_1: float [Default: 2e-05]
#    train_learning_rate_phase_2: float [Default: 6e-06]
#    train_max_batch_len: int [Default: 5000.0]
#    train_nnodes: int [Default: 2.0]
#    train_nproc_per_node: int [Default: 2.0]
#    train_num_epochs_phase_1: int [Default: 7.0]
#    train_num_epochs_phase_2: int [Default: 10.0]
#    train_num_warmup_steps_phase_1: int [Default: 1000.0]
#    train_num_warmup_steps_phase_2: int [Default: 1000.0]
#    train_save_samples: int [Default: 250000.0]
#    train_seed: int [Default: 42.0]
components:
  comp-createpvc:
    executorLabel: exec-createpvc
    inputDefinitions:
      parameters:
        access_modes:
          description: 'AccessModes to request for the provisioned PVC. May

            be one or more of ``''ReadWriteOnce''``, ``''ReadOnlyMany''``, ``''ReadWriteMany''``,
            or

            ``''ReadWriteOncePod''``. Corresponds to `PersistentVolumeClaim.spec.accessModes
            <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes>`_.'
          parameterType: LIST
        annotations:
          description: Annotations for the PVC's metadata. Corresponds to `PersistentVolumeClaim.metadata.annotations
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaim>`_.
          isOptional: true
          parameterType: STRUCT
        pvc_name:
          description: 'Name of the PVC. Corresponds to `PersistentVolumeClaim.metadata.name
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaim>`_.
            Only one of ``pvc_name`` and ``pvc_name_suffix`` can

            be provided.'
          isOptional: true
          parameterType: STRING
        pvc_name_suffix:
          description: 'Prefix to use for a dynamically generated name, which

            will take the form ``<argo-workflow-name>-<pvc_name_suffix>``. Only one

            of ``pvc_name`` and ``pvc_name_suffix`` can be provided.'
          isOptional: true
          parameterType: STRING
        size:
          description: The size of storage requested by the PVC that will be provisioned.
            For example, ``'5Gi'``. Corresponds to `PersistentVolumeClaim.spec.resources.requests.storage
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaimSpec>`_.
          parameterType: STRING
        storage_class_name:
          defaultValue: ''
          description: 'Name of StorageClass from which to provision the PV

            to back the PVC. ``None`` indicates to use the cluster''s default

            storage_class_name. Set to ``''''`` for a statically specified PVC.'
          isOptional: true
          parameterType: STRING
        volume_name:
          description: 'Pre-existing PersistentVolume that should back the

            provisioned PersistentVolumeClaim. Used for statically

            specified PV only. Corresponds to `PersistentVolumeClaim.spec.volumeName
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaimSpec>`_.'
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      parameters:
        name:
          parameterType: STRING
  comp-createpvc-2:
    executorLabel: exec-createpvc-2
    inputDefinitions:
      parameters:
        access_modes:
          description: 'AccessModes to request for the provisioned PVC. May

            be one or more of ``''ReadWriteOnce''``, ``''ReadOnlyMany''``, ``''ReadWriteMany''``,
            or

            ``''ReadWriteOncePod''``. Corresponds to `PersistentVolumeClaim.spec.accessModes
            <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes>`_.'
          parameterType: LIST
        annotations:
          description: Annotations for the PVC's metadata. Corresponds to `PersistentVolumeClaim.metadata.annotations
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaim>`_.
          isOptional: true
          parameterType: STRUCT
        pvc_name:
          description: 'Name of the PVC. Corresponds to `PersistentVolumeClaim.metadata.name
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaim>`_.
            Only one of ``pvc_name`` and ``pvc_name_suffix`` can

            be provided.'
          isOptional: true
          parameterType: STRING
        pvc_name_suffix:
          description: 'Prefix to use for a dynamically generated name, which

            will take the form ``<argo-workflow-name>-<pvc_name_suffix>``. Only one

            of ``pvc_name`` and ``pvc_name_suffix`` can be provided.'
          isOptional: true
          parameterType: STRING
        size:
          description: The size of storage requested by the PVC that will be provisioned.
            For example, ``'5Gi'``. Corresponds to `PersistentVolumeClaim.spec.resources.requests.storage
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaimSpec>`_.
          parameterType: STRING
        storage_class_name:
          defaultValue: ''
          description: 'Name of StorageClass from which to provision the PV

            to back the PVC. ``None`` indicates to use the cluster''s default

            storage_class_name. Set to ``''''`` for a statically specified PVC.'
          isOptional: true
          parameterType: STRING
        volume_name:
          description: 'Pre-existing PersistentVolume that should back the

            provisioned PersistentVolumeClaim. Used for statically

            specified PV only. Corresponds to `PersistentVolumeClaim.spec.volumeName
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaimSpec>`_.'
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      parameters:
        name:
          parameterType: STRING
  comp-createpvc-3:
    executorLabel: exec-createpvc-3
    inputDefinitions:
      parameters:
        access_modes:
          description: 'AccessModes to request for the provisioned PVC. May

            be one or more of ``''ReadWriteOnce''``, ``''ReadOnlyMany''``, ``''ReadWriteMany''``,
            or

            ``''ReadWriteOncePod''``. Corresponds to `PersistentVolumeClaim.spec.accessModes
            <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes>`_.'
          parameterType: LIST
        annotations:
          description: Annotations for the PVC's metadata. Corresponds to `PersistentVolumeClaim.metadata.annotations
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaim>`_.
          isOptional: true
          parameterType: STRUCT
        pvc_name:
          description: 'Name of the PVC. Corresponds to `PersistentVolumeClaim.metadata.name
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaim>`_.
            Only one of ``pvc_name`` and ``pvc_name_suffix`` can

            be provided.'
          isOptional: true
          parameterType: STRING
        pvc_name_suffix:
          description: 'Prefix to use for a dynamically generated name, which

            will take the form ``<argo-workflow-name>-<pvc_name_suffix>``. Only one

            of ``pvc_name`` and ``pvc_name_suffix`` can be provided.'
          isOptional: true
          parameterType: STRING
        size:
          description: The size of storage requested by the PVC that will be provisioned.
            For example, ``'5Gi'``. Corresponds to `PersistentVolumeClaim.spec.resources.requests.storage
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaimSpec>`_.
          parameterType: STRING
        storage_class_name:
          defaultValue: ''
          description: 'Name of StorageClass from which to provision the PV

            to back the PVC. ``None`` indicates to use the cluster''s default

            storage_class_name. Set to ``''''`` for a statically specified PVC.'
          isOptional: true
          parameterType: STRING
        volume_name:
          description: 'Pre-existing PersistentVolume that should back the

            provisioned PersistentVolumeClaim. Used for statically

            specified PV only. Corresponds to `PersistentVolumeClaim.spec.volumeName
            <https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/#PersistentVolumeClaimSpec>`_.'
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      parameters:
        name:
          parameterType: STRING
  comp-deletepvc:
    executorLabel: exec-deletepvc
    inputDefinitions:
      parameters:
        pvc_name:
          description: Name of the PVC to delete. Supports passing a runtime-generated
            name, such as a name provided by ``kubernetes.CreatePvcOp().outputs['name']``.
          parameterType: STRING
  comp-deletepvc-2:
    executorLabel: exec-deletepvc-2
    inputDefinitions:
      parameters:
        pvc_name:
          description: Name of the PVC to delete. Supports passing a runtime-generated
            name, such as a name provided by ``kubernetes.CreatePvcOp().outputs['name']``.
          parameterType: STRING
  comp-deletepvc-3:
    executorLabel: exec-deletepvc-3
    inputDefinitions:
      parameters:
        pvc_name:
          description: Name of the PVC to delete. Supports passing a runtime-generated
            name, such as a name provided by ``kubernetes.CreatePvcOp().outputs['name']``.
          parameterType: STRING
  comp-git-clone-op:
    executorLabel: exec-git-clone-op
    inputDefinitions:
      parameters:
        repo_branch:
          parameterType: STRING
        repo_pr:
          parameterType: NUMBER_INTEGER
        repo_url:
          parameterType: STRING
        taxonomy_path:
          defaultValue: /data/taxonomy
          isOptional: true
          parameterType: STRING
  comp-importer:
    executorLabel: exec-importer
    inputDefinitions:
      parameters:
        uri:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-importer-2:
    executorLabel: exec-importer-2
    inputDefinitions:
      parameters:
        uri:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-mock-op:
    executorLabel: exec-mock-op
  comp-mock-op-10:
    executorLabel: exec-mock-op-10
  comp-mock-op-11:
    executorLabel: exec-mock-op-11
  comp-mock-op-2:
    executorLabel: exec-mock-op-2
  comp-mock-op-3:
    executorLabel: exec-mock-op-3
  comp-mock-op-4:
    executorLabel: exec-mock-op-4
  comp-mock-op-5:
    executorLabel: exec-mock-op-5
  comp-mock-op-6:
    executorLabel: exec-mock-op-6
  comp-mock-op-7:
    executorLabel: exec-mock-op-7
  comp-mock-op-8:
    executorLabel: exec-mock-op-8
  comp-mock-op-9:
    executorLabel: exec-mock-op-9
  comp-model-to-pvc-op:
    executorLabel: exec-model-to-pvc-op
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        pvc_path:
          defaultValue: /model
          isOptional: true
          parameterType: STRING
  comp-model-to-pvc-op-2:
    executorLabel: exec-model-to-pvc-op-2
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        pvc_path:
          defaultValue: /model
          isOptional: true
          parameterType: STRING
  comp-sdg-op:
    executorLabel: exec-sdg-op
    inputDefinitions:
      parameters:
        num_instructions_to_generate:
          parameterType: NUMBER_INTEGER
        pipeline:
          parameterType: STRING
        repo_branch:
          parameterType: STRING
        repo_pr:
          parameterType: NUMBER_INTEGER
        sdg_path:
          defaultValue: /data/sdg
          isOptional: true
          parameterType: STRING
        sdg_sampling_size:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        taxonomy_path:
          defaultValue: /data/taxonomy
          isOptional: true
          parameterType: STRING
  comp-sdg-to-artifact-op:
    executorLabel: exec-sdg-to-artifact-op
    inputDefinitions:
      parameters:
        pvc_path:
          defaultValue: /data/sdg
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        sdg:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-taxonomy-to-artifact-op:
    executorLabel: exec-taxonomy-to-artifact-op
    inputDefinitions:
      parameters:
        pvc_path:
          defaultValue: /data/taxonomy
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        taxonomy:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-createpvc:
      container:
        image: argostub/createpvc
    exec-createpvc-2:
      container:
        image: argostub/createpvc
    exec-createpvc-3:
      container:
        image: argostub/createpvc
    exec-deletepvc:
      container:
        image: argostub/deletepvc
    exec-deletepvc-2:
      container:
        image: argostub/deletepvc
    exec-deletepvc-3:
      container:
        image: argostub/deletepvc
    exec-git-clone-op:
      container:
        args:
        - "\n            # Increase logging verbosity\n            set -x &&\n\n \
          \           # Add TLS Parameters if CA Cert exists and is non-zero size\n\
          \            ADDITIONAL_CLONE_PARAMS=\"\"\n            if [ -s \"$TAXONOMY_CA_CERT_PATH\"\
          \ ]; then\n                ADDITIONAL_CLONE_PARAMS=\"-c http.sslVerify=true\
          \ -c http.sslCAInfo=$TAXONOMY_CA_CERT_PATH\"\n            fi\n\n       \
          \     # Clone Taxonomy Repo\n            git clone $ADDITIONAL_CLONE_PARAMS\
          \ {{$.inputs.parameters['repo_url']}} {{$.inputs.parameters['taxonomy_path']}}\
          \ &&\n            cd {{$.inputs.parameters['taxonomy_path']}} &&\n\n   \
          \         # Run additional configuration if TLS certs provided\n       \
          \     if [ -s \"$TAXONOMY_CA_CERT_PATH\" ]; then\n                git config\
          \ http.sslVerify true &&\n                git config http.sslCAInfo $TAXONOMY_CA_CERT_PATH\n\
          \            fi &&\n\n            # Checkout and use taxonomy repo branch\
          \ or PR if specified\n            if [ -n \"{{$.inputs.parameters['repo_branch']}}\"\
          \ ]; then\n                git fetch origin {{$.inputs.parameters['repo_branch']}}\
          \ && git checkout {{$.inputs.parameters['repo_branch']}};\n            elif\
          \ [ -n \"{{$.inputs.parameters['repo_pr']}}\" ] && [ {{$.inputs.parameters['repo_pr']}}\
          \ -gt 0 ]; then\n                git fetch origin pull/{{$.inputs.parameters['repo_pr']}}/head:{{$.inputs.parameters['repo_pr']}}\
          \ && git checkout {{$.inputs.parameters['repo_pr']}};\n            fi\n\
          \            "
        command:
        - /bin/sh
        - -c
        env:
        - name: TAXONOMY_CA_CERT_PATH
          value: /tmp/cert/taxonomy-ca.crt
        image: registry.redhat.io/ubi9/toolbox@sha256:da31dee8904a535d12689346e65e5b00d11a6179abf1fa69b548dbd755fa2770
    exec-importer:
      importer:
        artifactUri:
          runtimeParameter: uri
        typeSchema:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
    exec-importer-2:
      importer:
        artifactUri:
          runtimeParameter: uri
        typeSchema:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
    exec-mock-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        env:
        - name: XDG_CACHE_HOME
          value: /tmp
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-10:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-11:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-3:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-4:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-5:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        env:
        - name: HOME
          value: /tmp
        - name: HF_HOME
          value: /tmp
        - name: JUDGE_CA_CERT_PATH
          value: /tmp/cert/ca.crt
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
        resources:
          accelerator:
            count: '1'
            type: nvidia.com/gpu
    exec-mock-op-6:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        env:
        - name: HOME
          value: /tmp
        - name: HF_HOME
          value: /tmp
        - name: JUDGE_CA_CERT_PATH
          value: /tmp/cert/ca.crt
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
        resources:
          accelerator:
            count: '1'
            type: nvidia.com/gpu
    exec-mock-op-7:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-8:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-mock-op-9:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - mock_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef mock_op():\n    pass\n\n"
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-model-to-pvc-op:
      container:
        args:
        - cp -r {{$.inputs.artifacts['model'].path}}/* {{$.inputs.parameters['pvc_path']}}
        command:
        - /bin/sh
        - -c
        image: registry.redhat.io/ubi9/toolbox@sha256:da31dee8904a535d12689346e65e5b00d11a6179abf1fa69b548dbd755fa2770
    exec-model-to-pvc-op-2:
      container:
        args:
        - cp -r {{$.inputs.artifacts['model'].path}}/* {{$.inputs.parameters['pvc_path']}}
        command:
        - /bin/sh
        - -c
        image: registry.redhat.io/ubi9/toolbox@sha256:da31dee8904a535d12689346e65e5b00d11a6179abf1fa69b548dbd755fa2770
    exec-sdg-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - sdg_op
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef sdg_op(\n    num_instructions_to_generate: int,\n    pipeline:\
          \ str,\n    repo_branch: Optional[str],\n    repo_pr: Optional[int],\n \
          \   taxonomy_path: str = \"/data/taxonomy\",\n    sdg_path: str = \"/data/sdg\"\
          ,\n    sdg_sampling_size: float = 1.0,\n):\n    import os\n    import shutil\n\
          \    import tempfile\n\n    import instructlab.sdg\n    import openai\n\
          \    import xdg_base_dirs\n    import yaml\n\n    api_key = os.getenv(\"\
          api_key\")\n    model = os.getenv(\"model\")\n    endpoint = os.getenv(\"\
          endpoint\")\n\n    sdg_ca_cert_path = os.getenv(\"SDG_CA_CERT_PATH\")\n\
          \    use_tls = os.path.exists(sdg_ca_cert_path) and (\n        os.path.getsize(sdg_ca_cert_path)\
          \ > 0\n    )\n    if use_tls:\n        import httpx\n\n        custom_http_client\
          \ = httpx.Client(verify=sdg_ca_cert_path)\n        client = openai.OpenAI(\n\
          \            base_url=endpoint, api_key=api_key, http_client=custom_http_client\n\
          \        )\n    else:\n        client = openai.OpenAI(base_url=endpoint,\
          \ api_key=api_key)\n\n    taxonomy_base = \"main\" if repo_branch or (repo_pr\
          \ and int(repo_pr) > 0) else \"empty\"\n\n    print(\"Generating synthetic\
          \ dataset for:\")\n    print()\n    print(\n        instructlab.sdg.utils.taxonomy.read_taxonomy(\n\
          \            taxonomy_path, taxonomy_base, document_output_dir=f\"{sdg_path}/documents\"\
          \n        )\n    )\n\n    # Generate synthetic dataset\n    # 1.0 is the\
          \ default size\n    if sdg_sampling_size == 1.0:\n        # generate_data\
          \ has a magic word for its taxonomy_base argument - 'empty'\n        # it\
          \ allows generating from the whole repo, see:\n        # https://github.com/instructlab/sdg/blob/c6a9e74a1618b1077cd38e713b8aaed8b7c0c8ce/src/instructlab/sdg/utils/taxonomy.py#L230\n\
          \        instructlab.sdg.generate_data(\n            client=client,\n  \
          \          num_instructions_to_generate=num_instructions_to_generate,\n\
          \            output_dir=sdg_path,\n            taxonomy=taxonomy_path,\n\
          \            taxonomy_base=taxonomy_base,\n            model_name=model,\n\
          \            pipeline=pipeline,\n            chunk_word_count=1000,\n  \
          \          server_ctx_size=4096,\n        )\n    # Tweak precomputed skills\
          \ data ratio if needed\n    else:\n        skills_recipe = \"/usr/share/instructlab/sdg/default_data_recipes/skills.yaml\"\
          \n\n        def set_precomputed_skills_data_ratio(sampling_size: float,\
          \ skills_recipe: str):\n            if os.path.exists(skills_recipe):\n\
          \                with open(skills_recipe, \"r\", encoding=\"utf-8\") as\
          \ file:\n                    skills_yaml = yaml.load(file, Loader=yaml.Loader)\n\
          \n                skills_yaml[\"datasets\"][0][\"sampling_size\"] = sampling_size\n\
          \n                with open(skills_recipe, \"w\", encoding=\"utf-8\") as\
          \ file:\n                    yaml.dump(skills_yaml, file)\n\n        try:\n\
          \            set_precomputed_skills_data_ratio(\n                sampling_size=sdg_sampling_size,\
          \ skills_recipe=skills_recipe\n            )\n        except PermissionError:\n\
          \            print(\"Failed to set precomputed skills data ratio: Permission\
          \ denied\")\n            print(\"Attempting to move default data recipes\
          \ to temporary directory\")\n\n            # Create a temporary directory\n\
          \            with tempfile.TemporaryDirectory() as temp_dir:\n         \
          \       # Create a default_data_recipes directory\n                temp_dir\
          \ = os.path.join(temp_dir, \"default_data_recipes\")\n                os.mkdir(temp_dir)\n\
          \n                # Copy default_data_recipes/skills.yaml to the temporary\
          \ directory\n                shutil.copy(skills_recipe, temp_dir)\n\n  \
          \              # Also copy the current pipeline directory to the temporary\
          \ directory - it's a small\n                # directory like 28KB\n    \
          \            # This isn't needed if the pipeline is either \"full\" or \"\
          simple\" but it's future-proofing\n                data_dirs = [\n     \
          \               os.path.join(str(dir), \"instructlab\", \"sdg\")\n     \
          \               for dir in xdg_base_dirs.xdg_data_dirs()\n             \
          \   ]\n                temp_pipeline_dir = os.path.join(temp_dir, \"pipeline\"\
          )\n                os.mkdir(temp_pipeline_dir)\n                for d in\
          \ data_dirs:\n                    pipeline_path = os.path.join(d, \"pipelines\"\
          , pipeline)\n                    if os.path.exists(pipeline_path):\n   \
          \                     shutil.copytree(\n                            pipeline_path,\n\
          \                            temp_pipeline_dir,\n                      \
          \      dirs_exist_ok=True,\n                        )\n                \
          \        break\n\n                # Build new skills.yaml path\n       \
          \         new_skills_recipe = os.path.join(temp_dir, \"skills.yaml\")\n\
          \                print(f\"New skills recipe path: {new_skills_recipe}\"\
          )\n\n                # Override XDG_DATA_DIRS with the temporary directory\n\
          \                # This allows SDG to read the new skills.yaml since it's\
          \ looking into XDG_DATA_DIRS\n                # and looks for a default_data_recipes\
          \ directory with a skills.yaml file\n                os.environ[\"XDG_DATA_DIRS\"\
          ] = f\"{temp_dir}\"\n\n                # Try to set the precomputed skills\
          \ data ratio again\n                try:\n                    set_precomputed_skills_data_ratio(\n\
          \                        sampling_size=sdg_sampling_size, skills_recipe=new_skills_recipe\n\
          \                    )\n                    print(\n                   \
          \     f\"Successfully set precomputed skills data ratio to {sdg_sampling_size}\"\
          \n                    )\n\n                    # generate_data has a magic\
          \ word for its taxonomy_base argument - 'empty'\n                    # it\
          \ allows generating from the whole repo, see:\n                    # https://github.com/instructlab/sdg/blob/c6a9e74a1618b1077cd38e713b8aaed8b7c0c8ce/src/instructlab/sdg/utils/taxonomy.py#L230\n\
          \                    instructlab.sdg.generate_data(\n                  \
          \      client=client,\n                        num_instructions_to_generate=num_instructions_to_generate,\n\
          \                        output_dir=sdg_path,\n                        taxonomy=taxonomy_path,\n\
          \                        taxonomy_base=taxonomy_base,\n                \
          \        model_name=model,\n                        pipeline=pipeline,\n\
          \                        chunk_word_count=1000,\n                      \
          \  server_ctx_size=4096,\n                    )\n                except\
          \ Exception as e:\n                    print(f\"Failed to set precomputed\
          \ skills data ratio: {e}\")\n                    raise\n\n"
        env:
        - name: HOME
          value: /tmp
        - name: HF_HOME
          value: /tmp
        - name: SDG_CA_CERT_PATH
          value: /tmp/cert/ca.crt
        image: registry.redhat.io/rhelai1/instructlab-nvidia-rhel9@sha256:05cfba1fb13ed54b1de4d021da2a31dd78ba7d8cc48e10c7fe372815899a18ae
    exec-sdg-to-artifact-op:
      container:
        args:
        - cp -r {{$.inputs.parameters['pvc_path']}} {{$.outputs.artifacts['sdg'].path}}
        command:
        - /bin/sh
        - -c
        image: registry.redhat.io/ubi9/toolbox@sha256:da31dee8904a535d12689346e65e5b00d11a6179abf1fa69b548dbd755fa2770
    exec-taxonomy-to-artifact-op:
      container:
        args:
        - cp -r {{$.inputs.parameters['pvc_path']}} {{$.outputs.artifacts['taxonomy'].path}}
        command:
        - /bin/sh
        - -c
        image: registry.redhat.io/ubi9/toolbox@sha256:da31dee8904a535d12689346e65e5b00d11a6179abf1fa69b548dbd755fa2770
pipelineInfo:
  description: InstructLab pipeline
  displayName: InstructLab
  name: instructlab
root:
  dag:
    tasks:
      createpvc:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-createpvc
        inputs:
          parameters:
            access_modes:
              runtimeValue:
                constant:
                - ReadWriteMany
            pvc_name_suffix:
              runtimeValue:
                constant: -sdg
            size:
              runtimeValue:
                constant: 10Gi
            storage_class_name:
              componentInputParameter: k8s_storage_class_name
        taskInfo:
          name: createpvc
      createpvc-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-createpvc-2
        inputs:
          parameters:
            access_modes:
              runtimeValue:
                constant:
                - ReadWriteMany
            pvc_name_suffix:
              runtimeValue:
                constant: -model-cache
            size:
              runtimeValue:
                constant: 100Gi
            storage_class_name:
              componentInputParameter: k8s_storage_class_name
        taskInfo:
          name: createpvc-2
      createpvc-3:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-createpvc-3
        inputs:
          parameters:
            access_modes:
              runtimeValue:
                constant:
                - ReadWriteMany
            pvc_name_suffix:
              runtimeValue:
                constant: -output
            size:
              runtimeValue:
                constant: 100Gi
            storage_class_name:
              componentInputParameter: k8s_storage_class_name
        taskInfo:
          name: createpvc-3
      deletepvc:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-deletepvc
        dependentTasks:
        - createpvc
        - mock-op-6
        inputs:
          parameters:
            pvc_name:
              taskOutputParameter:
                outputParameterKey: name
                producerTask: createpvc
        taskInfo:
          name: deletepvc
      deletepvc-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-deletepvc-2
        dependentTasks:
        - createpvc-2
        - mock-op-6
        inputs:
          parameters:
            pvc_name:
              taskOutputParameter:
                outputParameterKey: name
                producerTask: createpvc-2
        taskInfo:
          name: deletepvc-2
      deletepvc-3:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-deletepvc-3
        dependentTasks:
        - createpvc-3
        - mock-op-10
        - mock-op-11
        - mock-op-7
        - mock-op-8
        - mock-op-9
        inputs:
          parameters:
            pvc_name:
              taskOutputParameter:
                outputParameterKey: name
                producerTask: createpvc-3
        taskInfo:
          name: deletepvc-3
      git-clone-op:
        cachingOptions: {}
        componentRef:
          name: comp-git-clone-op
        dependentTasks:
        - createpvc
        inputs:
          parameters:
            repo_branch:
              componentInputParameter: sdg_repo_branch
            repo_pr:
              componentInputParameter: sdg_repo_pr
            repo_url:
              componentInputParameter: sdg_repo_url
        taskInfo:
          name: git-clone-op
      importer:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-importer
        inputs:
          parameters:
            uri:
              componentInputParameter: sdg_base_model
        taskInfo:
          name: importer
      importer-2:
        cachingOptions: {}
        componentRef:
          name: comp-importer-2
        dependentTasks:
        - createpvc-2
        inputs:
          parameters:
            uri:
              componentInputParameter: sdg_base_model
        taskInfo:
          name: importer-2
      mock-op:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op
        dependentTasks:
        - createpvc
        - createpvc-2
        - model-to-pvc-op
        - sdg-op
        taskInfo:
          name: mock-op
      mock-op-10:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-10
        dependentTasks:
        - createpvc-3
        - mock-op-6
        taskInfo:
          name: mock-op-10
      mock-op-11:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-11
        dependentTasks:
        - createpvc-3
        - mock-op-6
        taskInfo:
          name: mock-op-11
      mock-op-2:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-2
        dependentTasks:
        - createpvc
        - mock-op
        taskInfo:
          name: mock-op-2
      mock-op-3:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-3
        dependentTasks:
        - createpvc
        - mock-op
        taskInfo:
          name: mock-op-3
      mock-op-4:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-4
        dependentTasks:
        - createpvc-3
        - model-to-pvc-op-2
        taskInfo:
          name: mock-op-4
      mock-op-5:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-5
        dependentTasks:
        - createpvc-3
        - mock-op-4
        taskInfo:
          name: mock-op-5
      mock-op-6:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-6
        dependentTasks:
        - createpvc
        - createpvc-2
        - createpvc-3
        - mock-op-5
        taskInfo:
          name: mock-op-6
      mock-op-7:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-7
        dependentTasks:
        - createpvc-3
        - mock-op-5
        taskInfo:
          name: mock-op-7
      mock-op-8:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-8
        dependentTasks:
        - createpvc-3
        - mock-op-5
        taskInfo:
          name: mock-op-8
      mock-op-9:
        cachingOptions: {}
        componentRef:
          name: comp-mock-op-9
        dependentTasks:
        - createpvc-3
        - mock-op-6
        taskInfo:
          name: mock-op-9
      model-to-pvc-op:
        cachingOptions: {}
        componentRef:
          name: comp-model-to-pvc-op
        dependentTasks:
        - createpvc-2
        - importer
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: artifact
                producerTask: importer
        taskInfo:
          name: model-to-pvc-op
      model-to-pvc-op-2:
        cachingOptions: {}
        componentRef:
          name: comp-model-to-pvc-op-2
        dependentTasks:
        - importer
        - mock-op
        - model-to-pvc-op
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: artifact
                producerTask: importer
        taskInfo:
          name: model-to-pvc-op-2
      sdg-op:
        cachingOptions: {}
        componentRef:
          name: comp-sdg-op
        dependentTasks:
        - createpvc
        - git-clone-op
        inputs:
          parameters:
            num_instructions_to_generate:
              componentInputParameter: sdg_scale_factor
            pipeline:
              componentInputParameter: sdg_pipeline
            repo_branch:
              componentInputParameter: sdg_repo_branch
            repo_pr:
              componentInputParameter: sdg_repo_pr
            sdg_sampling_size:
              componentInputParameter: sdg_sample_size
        taskInfo:
          name: sdg-op
      sdg-to-artifact-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-sdg-to-artifact-op
        dependentTasks:
        - createpvc
        - git-clone-op
        - sdg-op
        taskInfo:
          name: sdg-to-artifact-op
      taxonomy-to-artifact-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-taxonomy-to-artifact-op
        dependentTasks:
        - createpvc
        - git-clone-op
        - sdg-op
        taskInfo:
          name: taxonomy-to-artifact-op
  inputDefinitions:
    parameters:
      final_eval_batch_size:
        defaultValue: auto
        description: Final model evaluation parameter for MMLU. Batch size for evaluation.
          Valid values are a positive integer or 'auto' to select the largest batch
          size that will fit in memory.
        isOptional: true
        parameterType: STRING
      final_eval_few_shots:
        defaultValue: 5.0
        description: Final model evaluation parameter for MMLU. Number of question-answer
          pairs provided in the context preceding the question used for evaluation.
        isOptional: true
        parameterType: NUMBER_INTEGER
      final_eval_max_workers:
        defaultValue: auto
        description: Final model evaluation parameter for MT Bench Branch. Number
          of workers to use for evaluation with mt_bench or mt_bench_branch. Must
          be a positive integer or 'auto'.
        isOptional: true
        parameterType: STRING
      final_eval_merge_system_user_message:
        defaultValue: false
        description: Final model evaluation parameter for MT Bench Branch. Boolean
          indicating whether to merge system and user messages (required for Mistral
          based judges)
        isOptional: true
        parameterType: BOOLEAN
      k8s_storage_class_name:
        defaultValue: standard
        description: A Kubernetes StorageClass name for persistent volumes. Selected
          StorageClass must support RWX PersistentVolumes.
        isOptional: true
        parameterType: STRING
      mt_bench_max_workers:
        defaultValue: auto
        description: MT Bench parameter. Number of workers to use for evaluation with
          mt_bench or mt_bench_branch. Must be a positive integer or 'auto'.
        isOptional: true
        parameterType: STRING
      mt_bench_merge_system_user_message:
        defaultValue: false
        description: MT Bench parameter. Boolean indicating whether to merge system
          and user messages (required for Mistral based judges)
        isOptional: true
        parameterType: BOOLEAN
      sdg_base_model:
        defaultValue: s3://<BUCKET>/<PATH_TO_MODEL>
        description: SDG parameter. LLM model used to generate the synthetic dataset
        isOptional: true
        parameterType: STRING
      sdg_max_batch_len:
        defaultValue: 5000.0
        description: SDG parameter. Maximum tokens per gpu for each batch that will
          be handled in a single step.
        isOptional: true
        parameterType: NUMBER_INTEGER
      sdg_pipeline:
        defaultValue: /usr/share/instructlab/sdg/pipelines/agentic
        description: 'SDG parameter. Data generation pipeline to use. Available: ''simple'',
          ''full'', or a valid path to a directory of pipeline workflow YAML files.
          Note that ''full'' requires a larger teacher model, Mixtral-8x7b.'
        isOptional: true
        parameterType: STRING
      sdg_pregenerated_tarball:
        description: SDG parameter.  Reference to a tarball that contains pre-generated
          SDG data (allows user to skip SDG step)
        isOptional: true
        parameterType: STRING
      sdg_repo_branch:
        description: SDG parameter. Points to a branch within the taxonomy git repository.
          If set, has priority over sdg_repo_pr
        isOptional: true
        parameterType: STRING
      sdg_repo_pr:
        description: SDG parameter. Points to a pull request against the taxonomy
          git repository
        isOptional: true
        parameterType: NUMBER_INTEGER
      sdg_repo_url:
        defaultValue: https://github.com/instructlab/taxonomy.git
        description: SDG parameter. Points to a taxonomy git repository
        isOptional: true
        parameterType: STRING
      sdg_sample_size:
        defaultValue: 1.0
        description: SDG parameter. Represents the sdg skills recipe sampling size
          as percentage in decimal form.
        isOptional: true
        parameterType: NUMBER_DOUBLE
      sdg_scale_factor:
        defaultValue: 30.0
        description: SDG parameter. The total number of instructions to be generated.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_effective_batch_size_phase_1:
        defaultValue: 128.0
        description: Training parameter for in Phase 1. The number of samples in a
          batch that the model should see before its parameters are updated.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_effective_batch_size_phase_2:
        defaultValue: 3840.0
        description: Training parameter for in Phase 2. The number of samples in a
          batch that the model should see before its parameters are updated.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_learning_rate_phase_1:
        defaultValue: 2.0e-05
        description: Training parameter for in Phase 1. How fast we optimize the weights
          during gradient descent. Higher values may lead to unstable learning performance.
          It's generally recommended to have a low learning rate with a high effective
          batch size.
        isOptional: true
        parameterType: NUMBER_DOUBLE
      train_learning_rate_phase_2:
        defaultValue: 6.0e-06
        description: Training parameter for in Phase 2. How fast we optimize the weights
          during gradient descent. Higher values may lead to unstable learning performance.
          It's generally recommended to have a low learning rate with a high effective
          batch size.
        isOptional: true
        parameterType: NUMBER_DOUBLE
      train_max_batch_len:
        defaultValue: 5000.0
        description: Training parameter. Maximum tokens per gpu for each batch that
          will be handled in a single step.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_nnodes:
        defaultValue: 2.0
        description: Training parameter. Number of nodes/workers to train on.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_nproc_per_node:
        defaultValue: 2.0
        description: Training parameter. Number of GPUs per each node/worker to use
          for training.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_num_epochs_phase_1:
        defaultValue: 7.0
        description: Training parameter for in Phase 1. Number of epochs to run training.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_num_epochs_phase_2:
        defaultValue: 10.0
        description: Training parameter for in Phase 2. Number of epochs to run training.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_num_warmup_steps_phase_1:
        defaultValue: 1000.0
        description: Training parameter for in Phase 1. The number of steps a model
          should go through before reaching the full learning rate. We start at 0
          and linearly climb up to train_learning_rate.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_num_warmup_steps_phase_2:
        defaultValue: 1000.0
        description: Training parameter for in Phase 2. The number of steps a model
          should go through before reaching the full learning rate. We start at 0
          and linearly climb up to train_learning_rate.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_save_samples:
        defaultValue: 250000.0
        description: Training parameter. Number of samples the model should see before
          saving a checkpoint.
        isOptional: true
        parameterType: NUMBER_INTEGER
      train_seed:
        defaultValue: 42.0
        description: Training parameter. Random seed for initializing training.
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.9.0
---
platforms:
  kubernetes:
    deploymentSpec:
      executors:
        exec-git-clone-op:
          configMapAsVolume:
          - configMapName: teacher-server
            mountPath: /tmp/cert
            optional: false
          pvcMount:
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
        exec-mock-op:
          pvcMount:
          - mountPath: /model
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-2
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
        exec-mock-op-10:
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
        exec-mock-op-11:
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
        exec-mock-op-2:
          pvcMount:
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
        exec-mock-op-3:
          pvcMount:
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
        exec-mock-op-4:
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
        exec-mock-op-5:
          configMapAsEnv:
          - configMapName: judge-server
            keyToEnv:
            - configMapKey: endpoint
              envVar: JUDGE_ENDPOINT
            - configMapKey: model
              envVar: JUDGE_NAME
          configMapAsVolume:
          - configMapName: judge-server
            mountPath: /tmp/cert
            optional: false
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
          secretAsEnv:
          - keyToEnv:
            - envVar: JUDGE_API_KEY
              secretKey: api_key
            secretName: judge-server
        exec-mock-op-6:
          configMapAsEnv:
          - configMapName: judge-server
            keyToEnv:
            - configMapKey: endpoint
              envVar: JUDGE_ENDPOINT
            - configMapKey: model
              envVar: JUDGE_NAME
          configMapAsVolume:
          - configMapName: judge-server
            mountPath: /tmp/cert
            optional: false
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
          - mountPath: /input
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
          - mountPath: /model
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-2
          secretAsEnv:
          - keyToEnv:
            - envVar: JUDGE_API_KEY
              secretKey: api_key
            secretName: judge-server
        exec-mock-op-7:
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
        exec-mock-op-8:
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
        exec-mock-op-9:
          pvcMount:
          - mountPath: /output
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-3
        exec-model-to-pvc-op:
          pvcMount:
          - mountPath: /model
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc-2
        exec-sdg-op:
          configMapAsEnv:
          - configMapName: teacher-server
            keyToEnv:
            - configMapKey: endpoint
              envVar: endpoint
            - configMapKey: model
              envVar: model
          configMapAsVolume:
          - configMapName: teacher-server
            mountPath: /tmp/cert
            optional: false
          pvcMount:
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
          secretAsEnv:
          - keyToEnv:
            - envVar: api_key
              secretKey: api_key
            secretName: teacher-server
        exec-sdg-to-artifact-op:
          pvcMount:
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
        exec-taxonomy-to-artifact-op:
          pvcMount:
          - mountPath: /data
            taskOutputParameter:
              outputParameterKey: name
              producerTask: createpvc
